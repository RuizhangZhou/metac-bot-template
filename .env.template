# Copy this file to `.env` and fill values. Never commit `.env` (it is gitignored).

# Required
METACULUS_TOKEN=YOUR_METACULUS_TOKEN

# Optional: second Metaculus token for tracking another account in digest mode
METACULUS_TRACK_TOKEN=YOUR_METACULUS_TRACK_TOKEN

# Optional: Digest comparison mode ("account" or "state")
DIGEST_COMPARE_MODE=account

# Optional: Limit questions per tournament for digest runs (useful for cheaper tests)
DIGEST_MAX_QUESTIONS_PER_TOURNAMENT=10

# Optional (pick what you actually use)
OPENROUTER_API_KEY=YOUR_OPENROUTER_API_KEY
PERPLEXITY_API_KEY=YOUR_PERPLEXITY_API_KEY
OPENAI_API_KEY=YOUR_OPENAI_API_KEY
EXA_API_KEY=YOUR_EXA_API_KEY
ASKNEWS_CLIENT_ID=YOUR_ASKNEWS_CLIENT_ID
ASKNEWS_SECRET=YOUR_ASKNEWS_SECRET
ANTHROPIC_API_KEY=YOUR_ANTHROPIC_API_KEY

# Optional: Use KIconnect as your non-search LLM (OpenAI-compatible proxy)
KICONNECT_API_URL=YOUR_KICONNECT_API_URL   # e.g. https://.../api/v1
KICONNECT_API_KEY=YOUR_KICONNECT_API_KEY   # format is typically "keyId:secret"
KICONNECT_MODEL=YOUR_KICONNECT_MODEL       # deployment/model name configured in KIconnect
KICONNECT_MODEL_FALLBACKS=                 # optional comma-separated, e.g. gpt-4.1,gpt-4o-mini,gpt-oss-120b

# Optional: LLM max_tokens (helps avoid OpenRouter low-credit errors)
BOT_MAX_TOKENS=4096

# Optional: model split (minimize web-search cost)
# - Forecasting/parsing uses BOT_BASE_MODEL (many calls).
# - Research uses BOT_SEARCH_MODEL (ideally 1 call per question).
# Cost-optimized setup:
#   - Use free reasoning model (gpt-oss-120b:free) for forecasting/parsing
#   - Use search model only for research (gpt-4o-mini-search-preview)
BOT_BASE_MODEL=openrouter/openai/gpt-oss-120b:free
BOT_SEARCH_MODEL=openrouter/openai/gpt-4o-mini-search-preview
BOT_ENABLE_WEB_SEARCH=true
# BOT_SINGLE_MODEL=openrouter/openai/gpt-4o-mini  # override everything with one model (debug/experiments)

# Optional: retries/timeouts (recommended for free models)
# Note: forecasting-tools retries can back off up to 60s between attempts; keeping base allowed tries low avoids long waits.
BOT_BASE_TIMEOUT_SECONDS=30
BOT_BASE_ALLOWED_TRIES=1

# Optional: Enable OpenRouter reasoning (auto-enabled for gpt-oss models)
BOT_ENABLE_REASONING=true

# Optional: Fallback model when free model hits rate limit
# If not set, auto-detects by removing ":free" suffix from BOT_BASE_MODEL
BOT_ENABLE_FALLBACK=true
BOT_FALLBACK_MODEL=openrouter/openai/gpt-oss-120b:free
BOT_FALLBACK_TIMEOUT_SECONDS=120
BOT_FALLBACK_ALLOWED_TRIES=2

# Optional: Safety guardrail - require KICONNECT_* env vars when using this template
# (prevents accidentally falling back to paid OpenAI models if OPENAI_API_KEY is set)
BOT_REQUIRE_KICONNECT=false

# Optional: Concurrency control (avoid rate limits on free models)
# Set to 1 to process questions sequentially (recommended for free models)
BOT_MAX_CONCURRENT_QUESTIONS=1
BOT_MAX_CONCURRENT_TASKS=1

# Optional: Tournament slugs/URLs (override workflow defaults without code changes)
METACULUS_CUP_TOURNAMENT=https://www.metaculus.com/tournament/metaculus-cup-spring-2026/
AIB_TOURNAMENT=https://www.metaculus.com/tournament/spring-aib-2026/
MARKET_PULSE_TOURNAMENT=https://www.metaculus.com/tournament/market-pulse-26q1/

# Optional: Matrix notifications (digest mode)
MATRIX_HOMESERVER=https://matrix.example.com
MATRIX_ACCESS_TOKEN=YOUR_MATRIX_BOT_ACCESS_TOKEN
MATRIX_ROOM_ID=!yourRoomId:example.com

# Optional: SmartSearcher tuning (when using --researcher smart-searcher/...)
SMART_SEARCHER_NUM_SEARCHES=1
SMART_SEARCHER_NUM_SITES_PER_SEARCH=5
SMART_SEARCHER_USE_ADVANCED_FILTERS=false
